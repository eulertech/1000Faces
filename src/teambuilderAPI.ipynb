{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the api to take the input from UI and return a list of EmployeeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to stopwords...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from autocorrect import spell\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt', 'stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    from nltk.stem import PorterStemmer\n",
    "    # remove non-alphabetic characters\n",
    "    textAlphabetic = re.sub('[^A-Za-z]', ' ', text)\n",
    "    # make all words lower case\n",
    "    textLower = textAlphabetic.lower()\n",
    "    # remove stop words\n",
    "    tokenized_text = word_tokenize(textLower)\n",
    "    for word in tokenized_text:\n",
    "        if word in stopwords.words('english'):\n",
    "            tokenized_text.remove(word)\n",
    "    # stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    for i in range(len(tokenized_text)):\n",
    "        tokenized_text[i] = stemmer.stem(spell(tokenized_text[i]))\n",
    "\n",
    "    return tokenized_text\n",
    "\n",
    "def stem_tokenize(text):\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(i) for i in word_tokenize(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input: text\n",
    "Return project ID list given a project ID: string\n",
    "Return a list.\n",
    "\"\"\"\n",
    "def predictTopKProject(text, topK = 5, vectorizer = 'countVectorizer.pkl',\n",
    "            embeddedProject = 'embeddedProject.csv',\n",
    "            employeeSimMatrix = 'employee_similarity_matrix.csv',\n",
    "           projectSimMatrix = 'project_similarity_matrix.csv'):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "    # load project embedding\n",
    "    embeddedProject = pd.read_csv('embeddedProject.csv',index_col = 'pID')\n",
    "    # preprocess\n",
    "    text_preprocessed = preprocess(text)\n",
    "    with open(vectorizer, 'rb') as f1:\n",
    "        vectorizer = pickle.load(f1)\n",
    "    \n",
    "    text_vectorized = vectorizer.transform([text]).toarray()\n",
    "    score = []\n",
    "    for i in range(embeddedProject.shape[0]):\n",
    "        prior_project = embeddedProject.iloc[i,:]\n",
    "        score.append(np.corrcoef(text_vectorized, prior_project)[0][1])\n",
    "    mylist = sorted(enumerate(score), key=lambda x: -x[1])\n",
    "    idx = [l[0] for l in mylist]\n",
    "    score_sorted = [l[1] for l in mylist]\n",
    "    pIds = [embeddedProject.index[ii] for ii in idx]\n",
    "    if topK == 'all':\n",
    "        return pIds\n",
    "    else:\n",
    "        return pIds[0:topK]\n",
    "\n",
    "\"\"\"\n",
    "input: a List of pIds\n",
    "Return employee ID list given a project ID: string\n",
    "Return a list.\n",
    "\"\"\"\n",
    "def getEmployeeIDForPid(pId, projectTablePath = r'../data/project_M25_matched.txt'):\n",
    "    if len(pId) == 0:\n",
    "        return None\n",
    "    project = pd.read_csv(projectTablePath,sep = '|', index_col = 'pID')\n",
    "    project.index = project.index.map(str)\n",
    "    eIds = []\n",
    "    for ids in pId:\n",
    "        eIds = eIds + project.loc[str(ids)]['ProjectTeam'].split(',')\n",
    "    return list(eIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTeam(text):\n",
    "    # get topK project\n",
    "    projectIdList = predictTopKProject(text)\n",
    "    print(projectIdList)\n",
    "    # get topK employee ID list\n",
    "    if len(projectIdList) > 0:\n",
    "        employeeIdList = getEmployeeIDForPid(projectIdList)\n",
    "        return employeeIdList\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 95, 9, 48, 28]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['12069', '12107', '12113', '12220', '12167']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputString = 'Tax, Payment and Compliance Solution meeting'\n",
    "buildTeam(inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
